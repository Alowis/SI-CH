geom_polygon(fill = "white", color = "gray10", size = 1) +
theme_bw(16)+
coord_fixed(xlim = longlims,  ylim = latlims, ratio = 1.3)
# file=paste0(getwd(),"/uerra_d1.nc")
# file=paste0(getwd(),"/Rain_era5_2010-2018.nc")
# filer=paste0(getwd(),"/PressurePrecipitation.nc")
# filew=paste0(getwd(),"/Wind_gust_ERA5_2018.nc")
fileele=paste0(getwd(),"/elev_0.1deg.nc")
elev<-nc_open(fileele)
name.var <- names(elev$var)
tdims=elev$ndims
tsize=c(1,1)
lonb<-c(which(round(elev$dim$longitude$vals,1)==longlims[1]-1),which(round(elev$dim$longitude$vals,1)==longlims[2]+1))
latb<-c(which(round(elev$dim$latitude$vals,1)==latlims[1]-1),which(round(elev$dim$latitude$vals,1)==latlims[2]+1))
countlon<-lonb[2]-lonb[1]+1
countlat<-latb[2]-latb[1]+1
start <- rep(1,tdims) # begin with start=(1,1,1,...,1)
start[1]<-lonb[1]
start[2]<-latb[1]
count <- tsize # begin w/count=(nx,ny,nz,...,nt), reads entire var
count[1]<-countlon
count[2]<-countlat
elevation<-list()
elevation$data   = ncvar_get(elev,name.var,start,count)
elevation$lon    = ncvar_get(elev,"longitude",start[1],count[1])
elevation$lat    = ncvar_get(elev,"latitude",start[2],count[2])
elonlat <- as.matrix(expand.grid(elevation$lon,elevation$lat))
ele1<-as.vector(elevation$data)
alelu<-data.frame(elonlat,ele1)
alelu$gr=1
ggplot(uk_fort, aes(x=long,y=lat,group=group)) +
theme_bw(16)+
coord_fixed(xlim = longlims,  ylim = latlims, ratio = 1.2)+
geom_raster(data=alelu,aes(x=Var1,y=Var2,fill=ele1,group=gr),alpha=.8,interpolate = T) +
scale_fill_gradientn(colours = terrain.colors(100),na.value = "aliceblue")+
geom_polygon(fill = "transparent", color = "gray10", size = 1.2)+
theme(axis.text=element_text(size=16),
axis.title=element_text(size=18,face="italic"),
panel.background = element_rect(fill = "white", colour = "grey50"),
legend.title = element_text(size=18),
legend.text = element_text(size=14),
legend.position = "none",
legend.key = element_rect(fill = "transparent", colour = "transparent"),
legend.key.size = unit(1, "cm"))+
scale_y_continuous(
breaks = c(48,50,52,54,56,58,60),limits = c(40,70),"Latitude")+
scale_x_continuous(
breaks =c(-6,-4,-2,0,2),limits=c(-10,10),"Longitiude")
#################################################################################
filer=paste0(getwd(),"/Rain_2009-2019.nc")
filew=paste0(getwd(),"/windG_2009-2019.nc")
ncr = nc_open(filer)
ncw = nc_open(filew)
ncatt_get(ncr,name.var,"long_name")
ncatt_get(ncw,name.var,"long_name")
haz<-c(filer,filew)
hazmat<-c()
for (h in 1:2){
nc = nc_open(haz[h])
nc$var$i10fg
nc$var$p0001
nc$var$p0005
file_time    <- ncvar_get(nc,'time')
file_time.info=nc$dim$time$units   # recherche la date initial de la variable time
file_time.origin=unlist(strsplit(file_time.info, " "))[[3]]
file_time.unit=unlist(strsplit(file_time.info, " "))[[1]]
if(length(nc$var)>1){
name.var <- names(nc$var)[1]}else{
name.var <- names(nc$var)
}
cat("Import parametre ", name.var,"\n")
name.lon="longitude"
name.lat="latitude"
nc$data   = ncvar_get(nc,name.var)
nc$lon    = ncvar_get(nc,name.lon)
nc$lat    = ncvar_get(nc,name.lat)
dlname <- ncatt_get(nc,name.var,"long_name")
dunits <- ncatt_get(nc,name.var,"units")
fillvalue <- ncatt_get(nc,name.var,"_FillValue")
dim(nc$lon)
dim(nc$lat)
time <- ncvar_get(nc,"time")
time
tunits <- ncatt_get(nc,"time","units")
nt <- dim(time)
nt
library(chron)
library(lattice)
library(RColorBrewer)
library(lubridate)
# nc$lat <- rev(nc$lat)
timestamp <- as_datetime(c(time*60*60),origin="1900-01-01")
timeb<-c(which(timestamp==Startdate),which(timestamp==Enddate))
lonb<-c(which(nc$lon==longlims[1]),which(nc$lon==longlims[2]))
latb<-c(which(nc$lat==latlims[1]),which(nc$lat==latlims[2]))
countime<-timeb[2]-timeb[1]+1
countlon<-lonb[2]-lonb[1]+1
countlat<-latb[2]-latb[1]+1
#
# tustr <- strsplit(tunits$value, " ")
# tdstr <- strsplit(unlist(tustr)[3], "-")
# ori<-as.Date(as.character(tdstr))
# tmonth <- as.integer(unlist(tdstr)[2])
# tday <- as.integer(unlist(tdstr)[3])
# tyear <- as.integer(unlist(tdstr)[1])
# tcrap<-strsplit(unlist(tustr)[4], ":")
# thour <- as.integer(unlist(tcrap)[1])
# time=as.vector(time)
# time<-time/24
# chron(time,origin=c(tmonth, tday, tyear,thour))
# nc$data[which(nc$data=="-32767")] <- NA
# nc$data[nc$data==fillvalue$value] <- NA
# length(na.omit(as.vector(nc$data[,,1])))
if(h==1){
t<-nc$var$tp
t<-nc$var$p0001
tsize<-t$varsize
tdims<-t$ndims
nt1<-tsize[tdims]
}
if(h==2){
t=nc$var$i10fg
t<-nc$var$p0001
tsize<-t$varsize
tdims<-t$ndims
nt1<-tsize[tdims]
}
#CHOOSE MY SPATIAL COVERAGE
#
# Initialize start and count to read one timestep of the variable.
start <- rep(1,tdims) # begin with start=(1,1,1,...,1)
start[tdims] <- timeb[1] # change to start=(1,1,1,...,i) to read timestep i
start[1]<-lonb[1]
start[2]<-latb[1]
count <- tsize # begin w/count=(nx,ny,nz,...,nt), reads entire var
count[1]<-countlon
count[2]<-countlat
count[tdims] <- countime # change to count=(nx,ny,nz,...,1) to read 1 tstep
#
if(count[2]<0)
{start[2]<-start[2]+count[2]-1
count[2]=-count[2]+2}
newformat<-list()
# tmp_array <- ncvar_get(nc,t, start = start, count= count)
newformat$data   = ncvar_get(nc,name.var, start = start, count= count)
newformat$lon    = ncvar_get(nc,name.lon,start = start[1], count= count[1])
newformat$lat    = nc$lat[seq(start[2],start[2]+count[2]-1)]
newformat$lat
newformat$lon
if(dlname$value=="Total precipitation") newformat$data<-newformat$data*1000
dlname <- ncatt_get(nc,name.var,"long_name")
dunits <- ncatt_get(nc,name.var,"units")
fillvalue <- ncatt_get(nc,name.var,"_FillValue")
time <- ncvar_get(nc,"time")
time<-time[seq(start[3],start[3]+count[3]-1)]
tunits <- ncatt_get(nc,"time","units")
nt <- dim(time)
which(timestamp== "2009-11-18 UTC")
temp11 <- newformat$data[ , , 7705]
for (merd in 1:36){
temp11=temp11+newformat$data[ , , 7705+merd] #Level is the third dimension and time the fourth.
}
# temp11<-temp11[,seq(length(temp11[1,]),1)]
#
# image(newformat$lon,newformat$lat,temp11,col=rev(brewer.pal(10,"RdBu")))
lon=newformat$lon
lat=newformat$lat
max(temp11)
rgb.palette=colorRampPalette(c("white",
"royalblue","orange","red","purple"),interpolate="linear",bias=1)
grid <- expand.grid(lon=lon, lat=lat)
cutpts <- c(1,5,10,15,20,25,30,35,40)
levelplot(temp11 ~ lon * lat, data=grid,cuts=50, pretty=T,
col.regions=(rgb.palette(200)))
hazmat<-c(hazmat,list(newformat))
}
tustr <- strsplit(tunits$value, " ")
library(chron)
library(lattice)
library(RColorBrewer)
library(dbscan)
library(dismo)
library(maps)
library(progress)
rbPal <- colorRampPalette(c('darkgreen',"gold","darkorange",'red'))
names(hazmat)=c("Pr","Wg")
#Set up a quantile for each grid cell
thr<-hazmat$Pr$data[,,1]
for (i in (1:33)){
for(j in 1:45){
crappy<-hazmat$Pr$data[i,j,]
thr[i,j]<-quantile(crappy[which(crappy>0)],.99,na.rm=T)
}
}
thw<-hazmat$Wg$data[,,1]
for (i in (1:33)){
for(j in 1:45){
crappy<-hazmat$Wg$data[i,j,]
thw[i,j]<-quantile(crappy[which(crappy>0)],.99,na.rm=T)
}
}
thrr<-as.vector(thw)
elonlat <- as.matrix(expand.grid(hazmat$Pr$lon,hazmat$Pr$lat))
thrbg<-data.frame(elonlat,thrr)
thrbg$gr=1
ggplot(uk_fort, aes(x=long,y=lat,group=group)) +
theme_bw(16)+
coord_fixed(xlim = longlims,  ylim = latlims, ratio = 1.2)+
geom_raster(data=thrbg,aes(x=Var1,y=Var2,fill=thrr,group=gr),alpha=.8,interpolate = F) +
scale_fill_gradientn(colours = rbPal(100),na.value = "aliceblue")+
geom_polygon(fill = "transparent", color = "gray10", size = 1.2)+
theme(axis.text=element_text(size=16),
axis.title=element_text(size=18,face="italic"),
panel.background = element_rect(fill = "white", colour = "grey50"),
legend.title = element_text(size=18),
legend.text = element_text(size=14),
legend.key = element_rect(fill = "transparent", colour = "transparent"),
legend.key.size = unit(1, "cm"))+
scale_y_continuous(
breaks = c(48,50,52,54,56,58,60),limits = c(40,70),"Latitude")+
scale_x_continuous(
breaks =c(-6,-4,-2,0,2),limits=c(-10,10),"Longitiude")
th1<-quantile(hazmat$Pr$data[which(hazmat[[1]]$data>0)],0.99,na.rm=T)
th2<-quantile(hazmat$Wg$data[which(hazmat[[2]]$data>0)],0.99,na.rm=T)
#####Spatiotemporal clustering#####
metaHaz<-list()
metavHour<-list()
metavDaz<-list()
for(hazard in 1:3){
if(hazard==1){hazdat=hazmat$Pr;th=thr}
if(hazard==2){hazdat=hazmat$Wg;th=thw}
if(hazard==3){hazdat1=hazmat$Pr;hazdat2=hazmat$Wg}
lon=hazmat$Pr$lon
lat=hazmat$Pr$lat
lonlatime <- expand.grid(lon, lat,time)
formeta<-hazmat$Pr$data
formeta2<-hazmat$Wg$data
if (hazard == 3){
bolilos<-hazdat1$data
bolilos[hazdat1$data<th1 | hazdat2$data<th2] <- NA
bolilos[hazdat1$data>=th1 & hazdat2$data>=th2] <- 1
formeta[hazdat1$data<th1 | hazdat2$data<th2] <- NA
formeta2[hazdat1$data<th1 | hazdat2$data<th2] <- NA
vectouf<- as.vector(bolilos)
length(na.omit(vectouf))
vrac<-as.vector(bolilos)
length(na.omit(vrac))
vecmeta<-as.vector(formeta)
vecmeta2<-as.vector(formeta2)
}else
{
bolilos<-hazdat$data
# boli<-bolilos[,,t]
# bol<-melt(boli)
# bol[which(bol[,3]<th),3]<-NA
# fmt<-array(as.matrix(bol$value), dim=c(33,45))
# formeta[,,t]<-fmt
# bol[which(bol[,3]>=th),3]<-1
# bolo<-array(as.matrix(bol$value), dim=c(33,45))
# bolilos[,,t]<-bolo
# bolilos[hazdat$data[,,t]<th] <- NA
vectouf<- as.vector(hazdat$data)
vecthouf<-as.vector(rep(th,length(bolilos[1,1,])))
vectouf[which(vectouf<vecthouf)]<-NA
vectouf[which(vectouf>=vecthouf)]<-1
vecmeta<-as.vector(formeta)
vecmeta2<-as.vector(formeta2)
if(hazard==1){vecmeta[which(vecmeta<vecthouf)] <- NA}
if(hazard==2){vecmeta2[which(vecmeta2<vecthouf)]<- NA}
}
lonlatemp <- data.frame(cbind(lonlatime,vectouf))
metav<-data.frame(cbind(lonlatime,vecmeta,vecmeta2))
#
# x=abs(rnorm(100*100,50,25))
# x=matrix(x,nrow=100)
# x1=melt(th)
if(hazard==1)metav<-metav[which(!is.na(metav[,4])),]
if(hazard==2)metav<-metav[which(!is.na(metav[,5])),]
if(hazard==3)metav<-metav[which(!is.na(metav[,5])),]
print(length(metav$Var1))
head(metav)
lonlatemp2<-lonlatemp[which(lonlatemp[,4]==1),]
spdata<-lonlatemp2[,-4]
print(length(spdata$Var1))
ep<-2
sampspd<-spdata
sampspd$Var1<-sampspd$Var1*16/5
sampspd$Var2<-sampspd$Var2*16/5
sampspd$Var3<-sampspd$Var3-sampspd$Var3[1]+1
sampspd$Var3<-sampspd$Var3
samptt<-as.matrix(sampspd)
# walabibou<-kNNdist(sampspd,k=15,all=F)
# plot(walabibou[order(walabibou)],ylim=c(0,4))
# abline(h=epcl, col=2)
# walabibou[order(walabibou)]
#
sqrt(0.5^2+0.5^2+1^2)
epcl=2
epl<-sqrt(.75^2+.75^2+1)
#
# reservo <- optics(sampspd,eps=100, minPts = 10)
# res=extractDBSCAN(reservo, eps_cl = ep)
# bip<-extractXi(object=res, xi=.2)
# reach=as.reachability(bip)
# dend<-as.dendrogram(reach)
#
if(hazard==1)weightc=metav$vecmeta
if(hazard==2)weightc=metav$vecmeta2
if(hazard==3)weightc=rep(1,length(sampspd[,1]))
rpip<-dbscan(sampspd, eps=epcl, minPts = 15,weights = weightc)
unique(rpip$cluster)
#
# nn<-frNN(sampspd,eps=epcl,sort=TRUE)
#
# i <- 100
# nn$id[[i]]
# nn$dist[[i]]
# plot(sampspd[,c(1,2)], col = ifelse(1:nrow(sampspd) %in% nn$id[[i]], "red", "black"))
#
# hist(sapply(adjacencylist(frchier), length),
#      xlab = "k", main="Number of Neighbors",
#      sub = paste("Neighborhood size eps =", frchier$eps))
#
# nn <- list(ids = list(c(2,3), c(1,3), c(1,2,3), c(3,5), c(4,5)), eps = 1)
# class(nn) <- c("NN", "frNN")
# nn
# head(adjacencylist(nn))
# dbscan(nn, minPts = 2)
# library(cluster)
# library(subspace)
# res1 <- extractDBSCAN(reservo, eps_cl = epcl)
# unique(res1$cluster)
# plot(res1)
# length(unique(res1$cluster))
# # hullplot(yip,res)
# plot(spdata[which(res1$cluster==87),c(1,2) ],col=res1$cluster)
spdata<-cbind(spdata,rpip$cluster)
if(length(which(spdata$`rpip$cluster`==0))>0){
metav<-metav[-which(spdata[,4]==0),]
spdata<-spdata[-which(spdata[,4]==0),]
}
metav$cluster<-spdata[,4]
length(spdata[,4])
length(metav[,4])
spdata$Var3=spdata$Var3-spdata$Var3[1]+1
length(metav$Var1)
length(spdata$Var1)
# for(m in unique(spdata[,4])){
metav$time<-as_datetime(c(metav$Var3*60*60),origin="1900-01-01")
metav$month=month(metav$time)
event<-metav
charloc<-paste(event[,1],event[,2])
event$cloc=charloc
print(length(event$Var1))
testev<-aggregate(list(rf= event[,4],wg=event[,5]),
by = list(ev = event[,6],loc=event[,9]),
FUN = function(x) c(sum = sum(na.omit(x)),max=max(na.omit(x))))
testev <- do.call(data.frame, testev)
thl<-aggregate(list(rf= event[,4],wg=event[,5]),
by = list(ev = event[,6]),
FUN = function(x) c(l= length(x)))
thl<- do.call(data.frame, thl)
small<-thl$ev[which(thl$rf<15)]
bip<-which(!is.na(match(testev$ev,small)))
testev<-testev[-bip,]
bop<-which(!is.na(match(event$cluster,small)))
event<-event[-bop,]
length(unique(event$cluster))
length(unique(testev$ev))
metamax<-aggregate(list(rf= testev[,3],wg=testev[,6]) ,
by = list(ev = testev[,1]),
FUN = function(x) c(sum = sum(na.omit(x)),max=max(na.omit(x)),mean=mean(x),sd=sd(x),surf=length(x)))
metamax<- do.call(data.frame, metamax)
metave<-aggregate(list(rf= event[,4],wg=event[,5]) ,
by = list(ev = event[,6]),
FUN = function(x) c(surf=length(x)))
metave <- do.call(data.frame, metave)
length(unique(metave$ev))
tempcom<-aggregate(event[,7] ,
by = list(ev = event[,6]),
FUN = function(x) c(dur=length(unique(x)),month=month(unique(x))[1],year=year(unique(x))[1]))
tempic<- do.call(data.frame, tempcom)
metave<-cbind(metamax,metave[,c(2,3)],tempic[,c(2,3,4)])
maxR<-c()
maxW<-c()
for (eve in unique(testev$ev))
{
evint<-testev[which(testev$ev==eve),]
met<-metamax[which(metamax$ev==eve),]
elR<-as.character(evint$loc[which(evint$rf.sum==met$rf.max)])[1]
elW<-as.character(evint$loc[which(evint$wg.max==met$wg.max)])[1]
maxR<-c(maxR,elR)
maxW<-c(maxW,elW)
}
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
Rcart=strsplit(maxR," ")
Rcar<-as.data.frame(matrix(unlist(Rcart),ncol=2,byrow=T))
Rcar[,1]<-as.numeric.factor((Rcar[,1]))
Rcar[,2]<-as.numeric.factor((Rcar[,2]))
Wcart=strsplit(maxW," ")
Wcar<-as.data.frame(matrix(unlist(Wcart),ncol=2,byrow=T))
Wcar[,1]<-as.numeric.factor((Wcar[,1]))
Wcar[,2]<-as.numeric.factor((Wcar[,2]))
EcWR=sqrt((Rcar[,1]-Wcar[,1])^2+(Rcar[,2]-Wcar[,2])^2)
geodist<-distGeo(Rcar,Wcar)/1000
plot(EcWR)
plot(geodist)
metave$season=metave$x.month
metave$season[which(metave$x.month<3 | metave$x.month>11)]=1
metave$season[which(metave$x.month<6 & metave$x.month>2)]=2
metave$season[which(metave$x.month<10 & metave$x.month>5)]=3
metave$season[which(metave$x.month<12& metave$x.month>9)]=4
metave$cv=metave$rf.sd/metave$rf.mean
metave$Dmax=geodist
metave$lonMR<-Rcar[,1]
metave$latMR<-Rcar[,2]
metave$lonMW<-Wcar[,1]
metave$latMW<-Wcar[,2]
metaveN<-metave
hist(metaveN$Dmax)
plot(metaveN$Dmax,metaveN$x.dur)
length(unique(metaveN$ev))
plot(metaveN$rf.max,metaveN$wg.max)
metaHaz<-c(metaHaz,list(metaveN))
metavHour<-c(metavHour,list(event))
metavDaz<-c(metavDaz,list(testev))
}
#Retain only events that affected lands
metaHax<-list()
metavHax<-list()
metavDax<-list()
for (hx in 1:3){
idout<-c()
for (cl in metaHaz[[hx]]$ev){
clev<-metavHour[[hx]][which(metavHour[[hx]]$cluster==cl),]
overlappy<-point.in.polygon(clev[,c(1)],clev[,c(2)],uk_fort$long,uk_fort$lat)
if(length(which(overlappy>0))==0)idout<-c(idout,cl)
}
idout
metax<-na.omit(match(idout,metaHaz[[hx]]$ev))
metat<-as.numeric(which(!is.na((match(metavHour[[hx]]$cluster,idout)))))
metas<-as.numeric(which(!is.na((match(metavDaz[[hx]]$ev,idout)))))
metar<-metaHaz[[hx]][-metax,]
metavr<-metavHour[[hx]][-metat,]
metasr<-metavDaz[[hx]][-metas,]
metaHax<-c(metaHax,list(metar))
metavHax<-c(metavHax,list(metavr))
metavDax<-c(metavDax,list(metasr))
}
############################################
#Then select of pairs of events that overlap spatially
if(newrun==T){
rep.row<-function(x,n){
matrix(rep(x,each=n),nrow=n)
}
rep.col<-function(x,n){
matrix(rep(x,each=n), ncol=n, byrow=TRUE)
}
oc<-c()
nvo<-c()
nwo<-c()
for (cl in metaHax[[1]]$ev){
clev<-metavDax[[1]][which(metavDax[[1]]$ev==cl),]
dd<-unique(metavHax[[1]]$time[which(metavHax[[1]]$cluster==cl)])
clex<-do.call(rbind, replicate(length(dd),clev[,c(1,2)], simplify=FALSE))
cley<-do.call(rbind, replicate(length(clev[,1]),as.data.frame(dd),simplify=F))
ouch<-cbind(clex,cley)
nvo<-rbind(nvo,ouch)
print(cl)
}
for (cl in metaHax[[2]]$ev){
clev<-metavDax[[2]][which(metavDax[[2]]$ev==cl),]
dd<-unique(metavHax[[2]]$time[which(metavHax[[2]]$cluster==cl)])
clex<-do.call(rbind, replicate(length(dd),clev[,c(1,2)], simplify=FALSE))
cley<-do.call(rbind, replicate(length(clev[,1]),as.data.frame(dd),simplify=F))
ouch<-cbind(clex,cley)
nwo<-rbind(nwo,ouch)
print(cl)
}
}else{
#these data frame contains spatial id and temporal id over the duration of an event of each cell involved in that event. (e.g., if the event last 10 hours, each cell involved will be repeated 10 times even if the the cell is only impacted during 1 hour)
# save(nvo,file="rainallclusters3.Rdata")
# save(nwo,file="windallclusters3.Rdata")
#
load(file="rainallclusters3.Rdata")
load(file="windallclusters3.Rdata")
}
clev<-metavHax[[1]]
cclev<-metavHax[[2]]
clev$charloc<-paste(clev$Var1,clev$Var2)
cclev$charloc<-paste(metavHax[[2]]$Var1,metavHax[[2]]$Var2)
sp10<-match_df(nvo,nwo,on=c("loc","dd"))
#Inner join in R:  Return only the rows in which the left table have matching keys in the right table
#this one set a pre-filter on events which have temporal overlap
sp03<-inner_join(nwo,nvo,by=c("loc","dd"))
length(unique(sp03$ev.x))
#aggregation by events and space, each row correpond to one cell involved in both rain and wind event
tesp<-aggregate(list(len=sp03[,3]),
by = list(ev2=sp03[,1],ev1 = sp03[,4],loc=sp03[,2]),
FUN = function(x) c(length=length(unique(x))))
tesp <- do.call(data.frame, tesp)
metatest<-metavHax[[1]]
#extract more metadata about the events
names(metavDax[[2]])[1]="ev2"
names(metatest)[c(6,7,9)]=c("ev.y","dd","loc")
metatest$meg<-paste(metatest$ev.y,metatest$dd,metatest$loc)
spkik$meg<-paste(spkik$ev.y,spkik$dd,spkik$loc)
spkik<-sp03 %>% group_by(ev.y,dd,loc) %>% mutate(id = row_number())
spkik$meg<-paste(spkik$ev.y,spkik$dd,spkik$loc)
sp20<-inner_join(metatest,spkik,by=c("meg"))
sp25<-sp20[which(sp20$id==1),]
length(unique(sp20$ev.x))
